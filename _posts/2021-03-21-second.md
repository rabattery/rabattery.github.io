---
layout: single
title:  'Explainable Artificial Intelligence (XAI): 설명가능한 인공지능'
excerpt: "리뷰논문 리뷰하기"
toc: true
toc_sticky: true
toc_label: '목차'

categories:
  - Review
tags:
  - XAI
  - Review
  - Deep learning
last_modified_at: 2021-03-21
comments : true
---
{:toc}

> _이번 포스팅에서는 **XAI**에 관한 리뷰논문을 정리해보고자 합니다._

리뷰하는 논문:
[Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI](https://www.sciencedirect.com/science/article/pii/S1566253519308103)

# 0. 들어가며
지난 몇 년동안 많은 응용 분야에서 AI는 괄목할만한 성과를 얻어냈습니다. 앙상블 또는 심층신경망과 같은 최신 기술은 종종 블랙박스로 표현되는데, 내부에서 무슨 일이 일어나는 지를 우리가 파악할 수 없게 된다는 걸 뜻합니다.
**블랙 박스**(*black-box*)의 반대는 **투명성**(*transparency*), 즉 모델이 작동하는 메커니즘에 대한 직접적인 이해를 찾는 것입니다. 
이러한 패러다임의 전환은 XAI분야의 발전을 촉진시키고 있습니다. 여러분은 이 논문 리뷰 포스트를 읽고, 어떤 접근방법이 기존에 검토되었는지 새로운 개념은 어떤 방식으로 제안되었는지 이해하시면 좋겠습니다!  
  
# 1. 소개
---------
블랙 박스 머신 러닝 모델이 점점 더 많이 사용됨에 따라 다양한 이해관계자들이 투명성에 대한 요구를 하고 있습니다. 정당 또는 합법적이지 않거나 행동에 대해 자세한 설명을 얻을 수 없는 결정을 만들고 사용하는 것이 큰 위험이기 때문입니다. 예로 들면 정밀 의학에서 전문가의 진단을 지원하거나, 자율 주행을 포함한 교통체계, 보안 및 금융 분야에서 이러한 요구가 클 것이라 예측할 수 있겠죠.
성능에만 집중하면 직관적으로 시스템이 점점 더 불투명해질 것이라고 생각할 수 있습니다. 모델의 성능과 투명성 간에는 분명 절충안이 있습니다. 만약 우리가 시스템에 대해 향상된 이해를 갖는다면, 결함을 수정할 수 있을 것입니다. 즉 구현 가능성이 향상되죠.
- __해석가능성__(*Interpretability*)은 의사결정(decision-making)의 공정성을 보장하는데 도움이 됩니다. 
- 해석가능성은 모델에 견고성을 제공합니다. 예를 들어 모델은 잠재적으로 예측 결과를 크게 흔들어버릴 수 있는 일종의 섭동을 감지할 수 있습니다.
- 해석가능성은 의미있는 변수만이 결과를 추론하는 보험 역할을 할 수 있습니다. 즉 모델의 추론에 근본적인 진실성 인과 관계가 존재함을 보장합니다.

즉 종합하면, **시스템의 해석이 실용적이다!**라고 주장하려면 모델메커니즘과 예측에 대해 이해하고, 규칙을 시각화 하거나 모델을 교란시킬 수 있는 잠재적 위협에 대한 힌트를 제공해야 함을 의미합니다.  

그러나 현재 세대의 최신 기술들의 효과를 제한하지 않기 위해, XAI는 다음 사항들이 요구됩니다.
1. 높은 수준의 학습 성능(예측 정확도 등)을 유지할 것
2. 인간이 새로운 파트너인 인공지능을 이해하고 적절하게 신뢰하고, 효과적으로 관리할 수 있도록 할 것

