---
layout: single
title:  'Explainable Artificial Intelligence (XAI): 설명가능한 인공지능 (3)'
excerpt: "Post-hoc explainability techniques"
toc: true
toc_sticky: true

categories:
  - Review
tags:
  - XAI
  - Review
  - Machine Learning
comments : true
header:
  image: '/assets/images/IMG_0001.JPG'
---
{:toc}


> _이번 포스팅에서는 **사후 설명 기술(Post-hoc explainability techniques)**에 대해 정리해보고자 합니다. 다양한 알고리즘 접근 방식을 분류하고 검토합니다:_  
> 1) 모든 종류의 ML 모델에 적용하도록 설계된 접근법  
> 2) 특정 ML모델을 위해 설계된 접근법

리뷰하는 논문:  
[Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI](https://www.sciencedirect.com/science/article/pii/S1566253519308103)

# 0. 들어가며
-------
ML 모델 자체가 transparent 기준을 충족하지 못하면, 별도의 방법을 고안하여 결정을 설명해야 합니다. 이는 이미 개발된 모델이 주어진 입력에 대해 예측을 생성하는 방법에 대한 이해 가능한 정보를 전달하는 것이 목적입니다. 
이 포스팅에서는 사
이전 포스트에서는 *transparent model*의 개념을 소개했습니다. 여기에 해당하는 모델은 우리가 설계단계에서 부터 작동원리를 이해하고 있는 ML 기법들이 속합니다. 이렇게 모델을 그 자체로 이해할 수 있는 경우 투명하다고 간주합니다.
![](https://ars.els-cdn.com/content/image/1-s2.0-S1566253519308103-gr5.jpg){: .align-center}
그림 1. 다양한 ML모델의 transparency level.

# 1. Linear/logistic regression
--------
Linear/logistic regression은 supervised learning에서 가장 간단한 분류 모델입니다. 이들은 transparent 모델의 특징인 algorithmic transparency, decomposability, simulatability를 가지고 있습니다.
비전문가인 청중들에게 모델을 설명할 때 약간의 시각화 도구만으로도 충분히 설명가능합니다. 그러나 모델의 size가 커지면 decomposability와 simulatability가 위협받습니다.
또한 highly engineered feature를 사용할 경우 모델은 decomposability와 점점 더 멀어집니다. 
# 2. Decision trees
--------
# 3. K-Nearest Neighbors
--------
# 4. Rule-based learning
--------
# 5. General additive models
--------
# 6. Bayesian models
--------
