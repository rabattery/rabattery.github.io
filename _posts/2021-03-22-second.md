---
layout: single
title:  'Explainable Artificial Intelligence (XAI): 설명가능한 인공지능 (3)'
excerpt: "Post-hoc explainability techniques"
toc: true
toc_sticky: true

categories:
  - Review
tags:
  - XAI
  - Review
  - Machine Learning
comments : true
header:
  image: '/assets/images/IMG_0001.JPG'
---
{:toc}


> _이번 포스팅에서는 **사후 설명 기술(Post-hoc explainability techniques)**에 대해 정리해보고자 합니다. 다양한 알고리즘 접근 방식을 분류하고 검토합니다:_  
> 1) 모든 종류의 ML 모델에 적용하도록 설계된 접근법  
> 2) 특정 ML모델을 위해 설계된 접근법

리뷰하는 논문:  
[Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI](https://www.sciencedirect.com/science/article/pii/S1566253519308103)

# 0. 들어가며
-------
ML 모델 자체가 transparent 기준을 충족하지 못하면, 별도의 방법을 고안하여 결정을 설명해야 합니다. 이는 이미 개발된 모델이 주어진 입력에 대해 예측을 생성하는 방법에 대한 이해 가능한 정보를 전달하는 것이 목적입니다. 
이 포스팅에서는 아래 순서에 따라 설명합니다.  
1. 내부 처리 또는 표현을 무시하고 모든 ML모델에 원활하게 적용할 수 있는 post-hoc explainability를 위한 model-agnostic techniques.
2. 특정 ML모델을 설명하기 위해 특별히 설계된 post-hoc explainability. 얕은 ML모델, 즉 신경처리장치의 계층 구조에 의존하지 않는 모든 ML모델의 post-hoc explainability.
3. Deep learning model, 즉 convolutional neural network(CNN), recurrent neural network(RNN) 및 관련 변형 모델과 더불어 Deep learning model과 transparent model을 포함하는 하이브리드 모델을 위해 고안된 기술.
4. 앞서 설명한 기술들의 보다 일반적인 분류법.

![](https://ars.els-cdn.com/content/image/1-s2.0-S1566253519308103-gr6.jpg){: .align-center}
그림 1. 다양한 ML모델과 관련된 XAI techniques  

# 1. Model-agnostic techniques for post-hoc explainability
--------
Model-agnostic 기술들은 예측 절차에서 일부 정보를 추출할 목적으로 모든 모델에 연결되도록 설계되었습니다. 이 기술은 *model simplification, feature relevance* estimation 그리고 *visualization*에 의존합니다.
- *Explanation by simplification*  simplification을 위한 거의 모든 기술은 규칙 추출 기술을 기반으로 합니다. 이 접근법에 대해 가장 잘 알려진 공헌 중 하나는 LIME(Local Interpretable Model-Agnostic Explanations)와 그 변종입니다. LIME은 locally linear model을 구축하여 opaque model을 설명합니다. G-REX라는 다른 접근법도 있습니다. 원래는 opaque model에서 규칙을 추출하는 것이 아니었지만, 확장된 G-REX는 여러 모델을 설명할 수 있습니다. 규칙을 추출하는 방법에 따라 복잡한 모델에서 human-interpretable model로 연결하기 위해 CNF(Conjunctive Normal Form) 또는 DNF(Disjunctive Normal Form)의 규칙을 학습하는 새로운 접근법이 연구되었습니다. 또다른 접근법은 복잡한 모델에 대해 투명한 모델을 근사화하여 model simplification을 모델 추출 과정으로 수식화한 것입니다. LIME 또는 G-REX와 같은 기술을 포함하여 모델 단순화의 인기는 분명합니다.
- *Feature relevance explanation* 이 기술은 모델의 예측 결과에서 각 feature가 갖는 영향, 관련성이나 중요도의 순위를 매기거나 측정을 통해 opaque model의 기능을 설명하는것을 목적으로 합니다. 동일한 목표를 가진 서로 다른 알고리즘적 접근방식에 의존하는 다양한 제안이 있습니다. 한가지 유익한 기여는 SHAP(Shapley Additive exPlanations)입니다. 각각의 예측에 대한 additive feature importance 점수를 계산하는 방법을 제시했습니다. 
# 2. Post-hoc explainability in shallow ML models
--------
## 2.1. Tree ensembles, random forests and multiple classifier systems

## 2.2. Support vector machines
# 3. Explainability in deep learning
--------
## 3.1. Multi-layer neural networks
## 3.2. Convolutional Neural Networks
## 3.3. Recurrent Neural Networks
## 3.4. Hybrid transparent and black-box methods
# 4. Alternative taxonomy of post-hoc explainability techniques for deep learning
--------
